diff --git a/examples/cluster/plot_cluster_comparison.py b/examples/cluster/plot_cluster_comparison.py
--- a/examples/cluster/plot_cluster_comparison.py
+++ b/examples/cluster/plot_cluster_comparison.py
@@ -178,6 +178,7 @@
         min_samples=params["hdbscan_min_samples"],
         min_cluster_size=params["hdbscan_min_cluster_size"],
         allow_single_cluster=params["allow_single_cluster"],
+        copy=True,
     )
     optics = cluster.OPTICS(
         min_samples=params["min_samples"],
diff --git a/examples/cluster/plot_hdbscan.py b/examples/cluster/plot_hdbscan.py
--- a/examples/cluster/plot_hdbscan.py
+++ b/examples/cluster/plot_hdbscan.py
@@ -108,7 +108,7 @@ def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=
 # clusters from all possible clusters (see :ref:`User Guide <HDBSCAN>`).
 # One immediate advantage is that HDBSCAN is scale-invariant.
 fig, axes = plt.subplots(3, 1, figsize=(10, 12))
-hdb = HDBSCAN()
+hdb = HDBSCAN(copy=True)
 for idx, scale in enumerate([1, 0.5, 3]):
     hdb.fit(X * scale)
     plot(
@@ -159,7 +159,7 @@ def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=
 # that DBSCAN is incapable of simultaneously separating the two dense clusters
 # while preventing the sparse clusters from fragmenting. Let's compare with
 # HDBSCAN.
-hdb = HDBSCAN().fit(X)
+hdb = HDBSCAN(copy=True).fit(X)
 plot(X, hdb.labels_, hdb.probabilities_)
 
 # %%
@@ -196,7 +196,7 @@ def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=
 PARAM = ({"min_cluster_size": 5}, {"min_cluster_size": 3}, {"min_cluster_size": 25})
 fig, axes = plt.subplots(3, 1, figsize=(10, 12))
 for i, param in enumerate(PARAM):
-    hdb = HDBSCAN(**param).fit(X)
+    hdb = HDBSCAN(copy=True, **param).fit(X)
     labels = hdb.labels_
 
     plot(X, labels, hdb.probabilities_, param, ax=axes[i])
@@ -219,7 +219,7 @@ def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=
 )
 fig, axes = plt.subplots(3, 1, figsize=(10, 12))
 for i, param in enumerate(PARAM):
-    hdb = HDBSCAN(**param).fit(X)
+    hdb = HDBSCAN(copy=True, **param).fit(X)
     labels = hdb.labels_
 
     plot(X, labels, hdb.probabilities_, param, ax=axes[i])
@@ -240,7 +240,7 @@ def plot(X, labels, probabilities=None, parameters=None, ground_truth=False, ax=
     {"cut_distance": 0.5},
     {"cut_distance": 1.0},
 )
-hdb = HDBSCAN()
+hdb = HDBSCAN(copy=True)
 hdb.fit(X)
 fig, axes = plt.subplots(len(PARAM), 1, figsize=(10, 12))
 for i, param in enumerate(PARAM):
diff --git a/examples/release_highlights/plot_release_highlights_1_3_0.py b/examples/release_highlights/plot_release_highlights_1_3_0.py
--- a/examples/release_highlights/plot_release_highlights_1_3_0.py
+++ b/examples/release_highlights/plot_release_highlights_1_3_0.py
@@ -58,7 +58,7 @@
 X, true_labels = load_digits(return_X_y=True)
 print(f"number of digits: {len(np.unique(true_labels))}")
 
-hdbscan = HDBSCAN(min_cluster_size=15).fit(X)
+hdbscan = HDBSCAN(min_cluster_size=15, copy=True).fit(X)
 non_noisy_labels = hdbscan.labels_[hdbscan.labels_ != -1]
 print(f"number of clusters found: {len(np.unique(non_noisy_labels))}")
 
diff --git a/sklearn/cluster/_hdbscan/hdbscan.py b/sklearn/cluster/_hdbscan/hdbscan.py
--- a/sklearn/cluster/_hdbscan/hdbscan.py
+++ b/sklearn/cluster/_hdbscan/hdbscan.py
@@ -55,7 +55,7 @@
 from sklearn.metrics._dist_metrics import DistanceMetric
 from sklearn.metrics.pairwise import _VALID_METRICS
 from sklearn.neighbors import BallTree, KDTree, NearestNeighbors
-from sklearn.utils._param_validation import Interval, StrOptions
+from sklearn.utils._param_validation import Hidden, Interval, StrOptions
 from sklearn.utils.validation import (
     _allclose_dense_sparse,
     _assert_all_finite,
@@ -534,6 +534,10 @@ class HDBSCAN(ClusterMixin, BaseEstimator):
         Currently, it only applies when `metric="precomputed"`, when passing
         a dense array or a CSR sparse matrix and when `algorithm="brute"`.
 
+        .. versionchanged:: 1.10
+            The default value for `copy` will change from `False` to `True`
+            in version 1.10.
+
     Attributes
     ----------
     labels_ : ndarray of shape (n_samples,)
@@ -624,9 +628,9 @@ class HDBSCAN(ClusterMixin, BaseEstimator):
     >>> from sklearn.cluster import HDBSCAN
     >>> from sklearn.datasets import load_digits
     >>> X, _ = load_digits(return_X_y=True)
-    >>> hdb = HDBSCAN(min_cluster_size=20)
+    >>> hdb = HDBSCAN(copy=True, min_cluster_size=20)
     >>> hdb.fit(X)
-    HDBSCAN(min_cluster_size=20)
+    HDBSCAN(copy=True, min_cluster_size=20)
     >>> hdb.labels_.shape == (X.shape[0],)
     True
     >>> np.unique(hdb.labels_).tolist()
@@ -655,7 +659,7 @@ class HDBSCAN(ClusterMixin, BaseEstimator):
         "cluster_selection_method": [StrOptions({"eom", "leaf"})],
         "allow_single_cluster": ["boolean"],
         "store_centers": [None, StrOptions({"centroid", "medoid", "both"})],
-        "copy": ["boolean"],
+        "copy": ["boolean", Hidden(StrOptions({"warn"}))],
     }
 
     def __init__(
@@ -673,7 +677,7 @@ def __init__(
         cluster_selection_method="eom",
         allow_single_cluster=False,
         store_centers=None,
-        copy=False,
+        copy="warn",
     ):
         self.min_cluster_size = min_cluster_size
         self.min_samples = min_samples
@@ -712,6 +716,18 @@ def fit(self, X, y=None):
         self : object
             Returns self.
         """
+        # TODO(1.10): remove "warn" option
+        # and leave copy to its default value where applicable in examples and doctests.
+        if self.copy == "warn":
+            warn(
+                "The default value of `copy` will change from False to True in 1.10."
+                " Explicitly set a value for `copy` to silence this warning.",
+                FutureWarning,
+            )
+            _copy = False
+        else:
+            _copy = self.copy
+
         if self.metric == "precomputed" and self.store_centers is not None:
             raise ValueError(
                 "Cannot store centers when using a precomputed distance matrix."
@@ -820,7 +836,7 @@ def fit(self, X, y=None):
 
             if self.algorithm == "brute":
                 mst_func = _hdbscan_brute
-                kwargs["copy"] = self.copy
+                kwargs["copy"] = _copy
             elif self.algorithm == "kd_tree":
                 mst_func = _hdbscan_prims
                 kwargs["algo"] = "kd_tree"
@@ -833,7 +849,7 @@ def fit(self, X, y=None):
             if issparse(X) or self.metric not in FAST_METRICS:
                 # We can't do much with sparse matrices ...
                 mst_func = _hdbscan_brute
-                kwargs["copy"] = self.copy
+                kwargs["copy"] = _copy
             elif self.metric in KDTree.valid_metrics:
                 # TODO: Benchmark KD vs Ball Tree efficiency
                 mst_func = _hdbscan_prims