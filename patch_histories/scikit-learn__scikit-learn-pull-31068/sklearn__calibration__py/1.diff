diff --git a/sklearn/calibration.py b/sklearn/calibration.py
--- a/sklearn/calibration.py
+++ b/sklearn/calibration.py
@@ -9,10 +9,10 @@
 from numbers import Integral, Real
 
 import numpy as np
-from scipy.optimize import minimize
+from scipy.optimize import minimize, minimize_scalar
 from scipy.special import expit
 
-from sklearn._loss import HalfBinomialLoss
+from sklearn._loss import HalfBinomialLoss, HalfMultinomialLoss
 from sklearn.base import (
     BaseEstimator,
     ClassifierMixin,
@@ -39,6 +39,7 @@
     _validate_style_kwargs,
 )
 from sklearn.utils._response import _get_response_values, _process_predict_proba
+from sklearn.utils.extmath import softmax
 from sklearn.utils.metadata_routing import (
     MetadataRouter,
     MethodMapping,
@@ -888,6 +889,57 @@ def loss_grad(AB):
     return AB_[0] / scale_constant, AB_[1]
 
 
+def _convert_to_logits(decision_values, eps=1e-12):
+    """Convert decision_function values to 2D and predict_proba values to logits.
+
+    This function ensures that the output of `decision_function` is
+    converted into a (n_samples, n_classes) array. For binary classification,
+    each row contains logits for the negative and positive classes as (-x, x).
+
+    If `predict_proba` is provided instead, it is converted into
+    log-probabilities using `numpy.log`.
+
+    Parameters
+    ----------
+    decision_values : array-like of shape (n_samples,) or (n_samples, 1) \
+        or (n_samples, n_classes).
+
+        The decision function values or probability estimates.
+        - If shape is (n_samples,), converts to (n_samples, 2) with (-x, x).
+        - If shape is (n_samples, 1), converts to (n_samples, 2) with (-x, x).
+        - If shape is (n_samples, n_classes), returns unchanged.
+        - For probability estimates, returns `numpy.log(decision_values + eps)`.
+
+    eps : float
+        Small positive value added to avoid log(0).
+
+    Returns
+    -------
+    logits : ndarray of shape (n_samples, n_classes)
+    """
+    decision_values = check_array(
+        decision_values, dtype=[np.float64, np.float32], ensure_2d=False
+    )
+    if (decision_values.ndim == 2) and (decision_values.shape[1] > 1):
+        # Check if it is the output of predict_proba
+        entries_zero_to_one = np.all((decision_values >= 0) & (decision_values <= 1))
+        row_sums_to_one = np.all(np.isclose(np.sum(decision_values, axis=1), 1.0))
+
+        if entries_zero_to_one and row_sums_to_one:
+            logits = np.log(decision_values + eps)
+        else:
+            logits = decision_values
+
+    elif (decision_values.ndim == 2) and (decision_values.shape[1] == 1):
+        logits = np.hstack([-decision_values, decision_values])
+
+    elif decision_values.ndim == 1:
+        decision_values = decision_values.reshape(-1, 1)
+        logits = np.hstack([-decision_values, decision_values])
+
+    return logits
+
+
 class _SigmoidCalibration(RegressorMixin, BaseEstimator):
     """Sigmoid regression model.
 
