diff --git a/sklearn/calibration.py b/sklearn/calibration.py
--- a/sklearn/calibration.py
+++ b/sklearn/calibration.py
@@ -713,12 +713,25 @@
     label_encoder = LabelEncoder().fit(classes)
     pos_class_indices = label_encoder.transform(clf.classes_)
     calibrators = []
-    for class_idx, this_pred in zip(pos_class_indices, predictions.T):
-        if method == "isotonic":
-            calibrator = IsotonicRegression(out_of_bounds="clip")
-        else:  # "sigmoid"
-            calibrator = _SigmoidCalibration()
-        calibrator.fit(this_pred, Y[:, class_idx], sample_weight)
+
+    if method in ("isotonic", "sigmoid"):
+        for class_idx, this_pred in zip(pos_class_indices, predictions.T):
+            if method == "isotonic":
+                calibrator = IsotonicRegression(out_of_bounds="clip")
+            else:  # "sigmoid"
+                calibrator = _SigmoidCalibration()
+            calibrator.fit(this_pred, Y[:, class_idx], sample_weight)
+            calibrators.append(calibrator)
+    elif method == "temperature":
+        if len(classes) == 2 and predictions.shape[-1] == 1:
+            response_method_name = _check_response_method(
+                clf,
+                ["decision_function", "predict_proba"],
+            ).__name__
+            if response_method_name == "predict_proba":
+                predictions = np.hstack([1 - predictions, predictions])
+        calibrator = _TemperatureScaling()
+        calibrator.fit(predictions, y, sample_weight)
         calibrators.append(calibrator)
 
     pipeline = _CalibratedClassifier(clf, calibrators, method=method, classes=classes)
@@ -785,27 +798,37 @@
         pos_class_indices = label_encoder.transform(self.estimator.classes_)
 
         proba = np.zeros((_num_samples(X), n_classes))
-        for class_idx, this_pred, calibrator in zip(
-            pos_class_indices, predictions.T, self.calibrators
-        ):
+
+        if self.method in ("sigmoid", "isotonic"):
+            for class_idx, this_pred, calibrator in zip(
+                pos_class_indices, predictions.T, self.calibrators
+            ):
+                if n_classes == 2:
+                    # When binary, `predictions` consists only of predictions for
+                    # clf.classes_[1] but `pos_class_indices` = 0
+                    class_idx += 1
+                proba[:, class_idx] = calibrator.predict(this_pred)
+            # Normalize the probabilities
             if n_classes == 2:
-                # When binary, `predictions` consists only of predictions for
-                # clf.classes_[1] but `pos_class_indices` = 0
-                class_idx += 1
-            proba[:, class_idx] = calibrator.predict(this_pred)
-
-        # Normalize the probabilities
-        if n_classes == 2:
-            proba[:, 0] = 1.0 - proba[:, 1]
-        else:
-            denominator = np.sum(proba, axis=1)[:, np.newaxis]
-            # In the edge case where for each class calibrator returns a null
-            # probability for a given sample, use the uniform distribution
-            # instead.
-            uniform_proba = np.full_like(proba, 1 / n_classes)
-            proba = np.divide(
-                proba, denominator, out=uniform_proba, where=denominator != 0
-            )
+                proba[:, 0] = 1.0 - proba[:, 1]
+            else:
+                denominator = np.sum(proba, axis=1)[:, np.newaxis]
+                # In the edge case where for each class calibrator returns a zero
+                # probability for a given sample, use the uniform distribution
+                # instead.
+                uniform_proba = np.full_like(proba, 1 / n_classes)
+                proba = np.divide(
+                    proba, denominator, out=uniform_proba, where=denominator != 0
+                )
+        elif self.method == "temperature":
+            if n_classes == 2 and predictions.shape[-1] == 1:
+                response_method_name = _check_response_method(
+                    self.estimator,
+                    ["decision_function", "predict_proba"],
+                ).__name__
+                if response_method_name == "predict_proba":
+                    predictions = np.hstack([1 - predictions, predictions])
+            proba = self.calibrators[0].predict(predictions)
 
         # Deal with cases where the predicted probability minimally exceeds 1.0
         proba[(1.0 < proba) & (proba <= 1.0 + 1e-5)] = 1.0
