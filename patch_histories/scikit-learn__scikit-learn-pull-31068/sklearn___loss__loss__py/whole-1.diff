diff --git a/sklearn/_loss/loss.py b/sklearn/_loss/loss.py
--- a/sklearn/_loss/loss.py
+++ b/sklearn/_loss/loss.py
@@ -457,6 +457,20 @@ def constant_to_optimal_zero(self, y_true, sample_weight=None):
         """Calculate term dropped in loss.
 
         With this term added, the loss of perfect predictions is zero.
+
+        Parameters
+        ----------
+        y_true : array-like of shape (n_samples,)
+            Observed, true target values.
+
+        sample_weight : None or array of shape (n_samples,), default=None
+            Sample weights.
+
+        Returns
+        -------
+        constant : ndarray of shape (n_samples,)
+            Constant value to be added to raw predictions so that the loss
+            of perfect predictions becomes zero.
         """
         return np.zeros_like(y_true)
 
@@ -982,8 +996,16 @@ class HalfMultinomialLoss(BaseLoss):
     classes: If the full hessian for classes k and l and sample i is H_i_k_l,
     we calculate H_i_k_k, i.e. k=l.
 
-    Reference
-    ---------
+    Parameters
+    ----------
+    sample_weight : {None, ndarray}
+        If sample_weight is None, the hessian might be constant.
+
+    n_classes : {None, int}
+        The number of classes for classification, else None.
+
+    References
+    ----------
     .. [1] :arxiv:`Simon, Noah, J. Friedman and T. Hastie.
         "A Blockwise Descent Algorithm for Group-penalized Multiresponse and
         Multinomial Regression".
@@ -1015,6 +1037,19 @@ def fit_intercept_only(self, y_true, sample_weight=None):
 
         This is the softmax of the weighted average of the target, i.e. over
         the samples axis=0.
+
+        Parameters
+        ----------
+        y_true : array-like of shape (n_samples,)
+            Observed, true target values.
+
+        sample_weight : None or array of shape (n_samples,), default=None
+            Sample weights.
+
+        Returns
+        -------
+        raw_prediction : numpy scalar or array of shape (n_classes,)
+            Raw predictions of an intercept-only model.
         """
         out = np.zeros(self.n_classes, dtype=y_true.dtype)
         eps = np.finfo(y_true.dtype).eps
