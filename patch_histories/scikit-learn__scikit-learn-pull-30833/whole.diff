diff --git a/sklearn/ensemble/_bagging.py b/sklearn/ensemble/_bagging.py
--- a/sklearn/ensemble/_bagging.py
+++ b/sklearn/ensemble/_bagging.py
@@ -202,14 +202,23 @@ def _parallel_build_estimators(
     return estimators, estimators_features
 
 
-def _parallel_predict_proba(estimators, estimators_features, X, n_classes):
+def _parallel_predict_proba(
+    estimators,
+    estimators_features,
+    X,
+    n_classes,
+    predict_params=None,
+    predict_proba_params=None,
+):
     """Private function used to compute (proba-)predictions within a job."""
     n_samples = X.shape[0]
     proba = np.zeros((n_samples, n_classes))
 
     for estimator, features in zip(estimators, estimators_features):
         if hasattr(estimator, "predict_proba"):
-            proba_estimator = estimator.predict_proba(X[:, features])
+            proba_estimator = estimator.predict_proba(
+                X[:, features], **(predict_params or {})
+            )
 
             if n_classes == len(estimator.classes_):
                 proba += proba_estimator
@@ -221,23 +230,25 @@ def _parallel_predict_proba(estimators, estimators_features, X, n_classes):
 
         else:
             # Resort to voting
-            predictions = estimator.predict(X[:, features])
+            predictions = estimator.predict(
+                X[:, features], **(predict_proba_params or {})
+            )
 
             for i in range(n_samples):
                 proba[i, predictions[i]] += 1
 
     return proba
 
 
-def _parallel_predict_log_proba(estimators, estimators_features, X, n_classes):
+def _parallel_predict_log_proba(estimators, estimators_features, X, n_classes, params):
     """Private function used to compute log probabilities within a job."""
     n_samples = X.shape[0]
     log_proba = np.empty((n_samples, n_classes))
     log_proba.fill(-np.inf)
     all_classes = np.arange(n_classes, dtype=int)
 
     for estimator, features in zip(estimators, estimators_features):
-        log_proba_estimator = estimator.predict_log_proba(X[:, features])
+        log_proba_estimator = estimator.predict_log_proba(X[:, features], **params)
 
         if n_classes == len(estimator.classes_):
             log_proba = np.logaddexp(log_proba, log_proba_estimator)
@@ -254,18 +265,18 @@ def _parallel_predict_log_proba(estimators, estimators_features, X, n_classes):
     return log_proba
 
 
-def _parallel_decision_function(estimators, estimators_features, X):
+def _parallel_decision_function(estimators, estimators_features, X, params):
     """Private function used to compute decisions within a job."""
     return sum(
-        estimator.decision_function(X[:, features])
+        estimator.decision_function(X[:, features], **params)
         for estimator, features in zip(estimators, estimators_features)
     )
 
 
-def _parallel_predict_regression(estimators, estimators_features, X):
+def _parallel_predict_regression(estimators, estimators_features, X, params):
     """Private function used to compute predictions within a job."""
     return sum(
-        estimator.predict(X[:, features])
+        estimator.predict(X[:, features], **params)
         for estimator, features in zip(estimators, estimators_features)
     )
 
@@ -615,10 +626,47 @@ def get_metadata_routing(self):
             routing information.
         """
         router = MetadataRouter(owner=self.__class__.__name__)
-        router.add(
-            estimator=self._get_estimator(),
-            method_mapping=MethodMapping().add(callee="fit", caller="fit"),
+
+        method_mapping = MethodMapping()
+        method_mapping.add(caller="fit", callee="fit").add(
+            caller="decision_function", callee="decision_function"
         )
+
+        # the router needs to be built depending on whether the sub-estimator has a
+        # `predict_proba` method (as BaggingClassifier decides dynamically at runtime):
+        if hasattr(self._get_estimator(), "predict_proba"):
+            (
+                method_mapping.add(caller="predict", callee="predict_proba").add(
+                    caller="predict_proba", callee="predict_proba"
+                )
+            )
+
+        else:
+            (
+                method_mapping.add(caller="predict", callee="predict").add(
+                    caller="predict_proba", callee="predict"
+                )
+            )
+
+        # the router needs to be built depending on whether the sub-estimator has a
+        # `predict_log_proba` method (as BaggingClassifier decides dynamically at
+        # runtime):
+        if hasattr(self._get_estimator(), "predict_log_proba"):
+            method_mapping.add(caller="predict_log_proba", callee="predict_log_proba")
+
+        else:
+            # if `predict_log_proba` is not available in BaggingClassifier's
+            # sub-estimator, the routing should go to its `predict_proba` if it is
+            # available or else to its `predict` method; according to how
+            # `sample_weight` is passed to the respective methods dynamically at
+            # runtime:
+            if hasattr(self._get_estimator(), "predict_proba"):
+                method_mapping.add(caller="predict_log_proba", callee="predict_proba")
+
+            else:
+                method_mapping.add(caller="predict_log_proba", callee="predict")
+
+        router.add(estimator=self._get_estimator(), method_mapping=method_mapping)
         return router
 
     @abstractmethod
@@ -882,7 +930,7 @@ def _validate_y(self, y):
 
         return y
 
-    def predict(self, X):
+    def predict(self, X, **params):
         """Predict class for X.
 
         The predicted class of an input sample is computed as the class with
@@ -895,15 +943,28 @@ def predict(self, X):
             The training input samples. Sparse matrices are accepted only if
             they are supported by the base estimator.
 
+        **params : dict
+            Parameters routed to the `predict_proba` (if available) or the `predict`
+            method (otherwise) of the sub-estimators via the metadata routing API.
+
+            .. versionadded:: 1.7
+
+                Only available if
+                `sklearn.set_config(enable_metadata_routing=True)` is set. See
+                :ref:`Metadata Routing User Guide <metadata_routing>` for more
+                details.
+
         Returns
         -------
         y : ndarray of shape (n_samples,)
             The predicted classes.
         """
-        predicted_probabilitiy = self.predict_proba(X)
+        _raise_for_params(params, self, "predict")
+
+        predicted_probabilitiy = self.predict_proba(X, **params)
         return self.classes_.take((np.argmax(predicted_probabilitiy, axis=1)), axis=0)
 
-    def predict_proba(self, X):
+    def predict_proba(self, X, **params):
         """Predict class probabilities for X.
 
         The predicted class probabilities of an input sample is computed as
@@ -919,12 +980,25 @@ def predict_proba(self, X):
             The training input samples. Sparse matrices are accepted only if
             they are supported by the base estimator.
 
+        **params : dict
+            Parameters routed to the `predict_proba` (if available) or the `predict`
+            method (otherwise) of the sub-estimators via the metadata routing API.
+
+            .. versionadded:: 1.7
+
+                Only available if
+                `sklearn.set_config(enable_metadata_routing=True)` is set. See
+                :ref:`Metadata Routing User Guide <metadata_routing>` for more
+                details.
+
         Returns
         -------
         p : ndarray of shape (n_samples, n_classes)
             The class probabilities of the input samples. The order of the
             classes corresponds to that in the attribute :term:`classes_`.
         """
+        _raise_for_params(params, self, "predict_proba")
+
         check_is_fitted(self)
         # Check data
         X = validate_data(
@@ -936,6 +1010,12 @@ def predict_proba(self, X):
             reset=False,
         )
 
+        if _routing_enabled():
+            routed_params = process_routing(self, "predict_proba", **params)
+        else:
+            routed_params = Bunch()
+            routed_params.estimator = Bunch(predict_proba=Bunch())
+
         # Parallel loop
         n_jobs, _, starts = _partition_estimators(self.n_estimators, self.n_jobs)
 
@@ -947,6 +1027,8 @@ def predict_proba(self, X):
                 self.estimators_features_[starts[i] : starts[i + 1]],
                 X,
                 self.n_classes_,
+                predict_params=routed_params.estimator.get("predict", None),
+                predict_proba_params=routed_params.estimator.get("predict_proba", None),
             )
             for i in range(n_jobs)
         )
@@ -956,7 +1038,7 @@ def predict_proba(self, X):
 
         return proba
 
-    def predict_log_proba(self, X):
+    def predict_log_proba(self, X, **params):
         """Predict class log-probabilities for X.
 
         The predicted class log-probabilities of an input sample is computed as
@@ -969,13 +1051,29 @@ def predict_log_proba(self, X):
             The training input samples. Sparse matrices are accepted only if
             they are supported by the base estimator.
 
+        **params : dict
+            Parameters routed to the `predict_log_proba`, the `predict_proba` or the
+            `proba` method of the sub-estimators via the metadata routing API. The
+            routing is tried in the mentioned order depending on whether this method is
+            available on the sub-estimator.
+
+            .. versionadded:: 1.7
+
+                Only available if
+                `sklearn.set_config(enable_metadata_routing=True)` is set. See
+                :ref:`Metadata Routing User Guide <metadata_routing>` for more
+                details.
+
         Returns
         -------
         p : ndarray of shape (n_samples, n_classes)
             The class log-probabilities of the input samples. The order of the
             classes corresponds to that in the attribute :term:`classes_`.
         """
+        _raise_for_params(params, self, "predict_log_proba")
+
         check_is_fitted(self)
+
         if hasattr(self.estimator_, "predict_log_proba"):
             # Check data
             X = validate_data(
@@ -987,6 +1085,12 @@ def predict_log_proba(self, X):
                 reset=False,
             )
 
+            if _routing_enabled():
+                routed_params = process_routing(self, "predict_log_proba", **params)
+            else:
+                routed_params = Bunch()
+                routed_params.estimator = Bunch(predict_log_proba=Bunch())
+
             # Parallel loop
             n_jobs, _, starts = _partition_estimators(self.n_estimators, self.n_jobs)
 
@@ -996,6 +1100,7 @@ def predict_log_proba(self, X):
                     self.estimators_features_[starts[i] : starts[i + 1]],
                     X,
                     self.n_classes_,
+                    params=routed_params.estimator.predict_log_proba,
                 )
                 for i in range(n_jobs)
             )
@@ -1009,14 +1114,14 @@ def predict_log_proba(self, X):
             log_proba -= np.log(self.n_estimators)
 
         else:
-            log_proba = np.log(self.predict_proba(X))
+            log_proba = np.log(self.predict_proba(X, **params))
 
         return log_proba
 
     @available_if(
         _estimator_has("decision_function", delegates=("estimators_", "estimator"))
     )
-    def decision_function(self, X):
+    def decision_function(self, X, **params):
         """Average of the decision functions of the base classifiers.
 
         Parameters
@@ -1025,6 +1130,17 @@ def decision_function(self, X):
             The training input samples. Sparse matrices are accepted only if
             they are supported by the base estimator.
 
+        **params : dict
+            Parameters routed to the `decision_function` method of the sub-estimators
+            via the metadata routing API.
+
+            .. versionadded:: 1.7
+
+                Only available if
+                `sklearn.set_config(enable_metadata_routing=True)` is set. See
+                :ref:`Metadata Routing User Guide <metadata_routing>` for more
+                details.
+
         Returns
         -------
         score : ndarray of shape (n_samples, k)
@@ -1033,6 +1149,8 @@ def decision_function(self, X):
             ``classes_``. Regression and binary classification are special
             cases with ``k == 1``, otherwise ``k==n_classes``.
         """
+        _raise_for_params(params, self, "decision_function")
+
         check_is_fitted(self)
 
         # Check data
@@ -1045,6 +1163,12 @@ def decision_function(self, X):
             reset=False,
         )
 
+        if _routing_enabled():
+            routed_params = process_routing(self, "decision_function", **params)
+        else:
+            routed_params = Bunch()
+            routed_params.estimator = Bunch(decision_function=Bunch())
+
         # Parallel loop
         n_jobs, _, starts = _partition_estimators(self.n_estimators, self.n_jobs)
 
@@ -1053,6 +1177,7 @@ def decision_function(self, X):
                 self.estimators_[starts[i] : starts[i + 1]],
                 self.estimators_features_[starts[i] : starts[i + 1]],
                 X,
+                params=routed_params.estimator.decision_function,
             )
             for i in range(n_jobs)
         )
@@ -1251,7 +1376,7 @@ def __init__(
             verbose=verbose,
         )
 
-    def predict(self, X):
+    def predict(self, X, **params):
         """Predict regression target for X.
 
         The predicted regression target of an input sample is computed as the
@@ -1263,11 +1388,24 @@ def predict(self, X):
             The training input samples. Sparse matrices are accepted only if
             they are supported by the base estimator.
 
+        **params : dict
+            Parameters routed to the `predict` method of the sub-estimators via the
+            metadata routing API.
+
+            .. versionadded:: 1.7
+
+                Only available if
+                `sklearn.set_config(enable_metadata_routing=True)` is set. See
+                :ref:`Metadata Routing User Guide <metadata_routing>` for more
+                details.
+
         Returns
         -------
         y : ndarray of shape (n_samples,)
             The predicted values.
         """
+        _raise_for_params(params, self, "predict")
+
         check_is_fitted(self)
         # Check data
         X = validate_data(
@@ -1279,6 +1417,12 @@ def predict(self, X):
             reset=False,
         )
 
+        if _routing_enabled():
+            routed_params = process_routing(self, "predict", **params)
+        else:
+            routed_params = Bunch()
+            routed_params.estimator = Bunch(predict=Bunch())
+
         # Parallel loop
         n_jobs, _, starts = _partition_estimators(self.n_estimators, self.n_jobs)
 
@@ -1287,6 +1431,7 @@ def predict(self, X):
                 self.estimators_[starts[i] : starts[i + 1]],
                 self.estimators_features_[starts[i] : starts[i + 1]],
                 X,
+                params=routed_params.estimator.predict,
             )
             for i in range(n_jobs)
         )