diff --git a/sklearn/linear_model/_base.py b/sklearn/linear_model/_base.py
--- a/sklearn/linear_model/_base.py
+++ b/sklearn/linear_model/_base.py
@@ -5,7 +5,6 @@
 # Authors: The scikit-learn developers
 # SPDX-License-Identifier: BSD-3-Clause
 
-import numbers
 import warnings
 from abc import ABCMeta, abstractmethod
 from numbers import Integral, Real
@@ -114,12 +113,14 @@ def _preprocess_data(
     copy_y=True,
     sample_weight=None,
     check_input=True,
+    rescale_with_sw=True,
 ):
     """Common data preprocessing for fitting linear models.
 
     This helper is in charge of the following steps:
 
-    - Ensure that `sample_weight` is an array or `None`.
+    - `sample_weight` is assumed to be `None` or a validated array with same dtype as
+      `X`.
     - If `check_input=True`, perform standard input validation of `X`, `y`.
     - Perform copies if requested to avoid side-effects in case of inplace
       modifications of the input.
@@ -138,6 +139,9 @@ def _preprocess_data(
     If `fit_intercept=False`, no centering is performed and `X_offset`, `y_offset`
     are set to zero.
 
+    If `rescale_with_sw` is True, then X and y are rescaled with the square root of
+    sample weights.
+
     Returns
     -------
     X_out : {ndarray, sparse matrix} of shape (n_samples, n_features)
@@ -153,16 +157,13 @@ def _preprocess_data(
     X_scale : ndarray of shape (n_features,)
         Always an array of ones. TODO: refactor the code base to make it
         possible to remove this unused variable.
+    sample_weight_sqrt : ndarray of shape (n_samples, ) or None
+        `np.sqrt(sample_weight)`
     """
     xp, _, device_ = get_namespace_and_device(X, y, sample_weight)
     n_samples, n_features = X.shape
     X_is_sparse = sp.issparse(X)
 
-    if isinstance(sample_weight, numbers.Number):
-        sample_weight = None
-    if sample_weight is not None:
-        sample_weight = xp.asarray(sample_weight)
-
     if check_input:
         X = check_array(
             X, copy=copy, accept_sparse=["csr", "csc"], dtype=supported_float_dtypes(xp)
@@ -199,12 +200,16 @@ def _preprocess_data(
     # XXX: X_scale is no longer needed. It is an historic artifact from the
     # time where linear model exposed the normalize parameter.
     X_scale = xp.ones(n_features, dtype=X.dtype, device=device_)
-    return X, y, X_offset, y_offset, X_scale
 
-
-# TODO: _rescale_data should be factored into _preprocess_data.
-# Currently, the fact that sag implements its own way to deal with
-# sample_weight makes the refactoring tricky.
+    if sample_weight is not None and rescale_with_sw:
+        # Sample weight can be implemented via a simple rescaling.
+        # For sparse X and y, it triggers copies anyway.
+        # For dense X and y that already have been copied, we safely do inplace
+        # rescaling.
+        X, y, sample_weight_sqrt = _rescale_data(X, y, sample_weight, inplace=copy)
+    else:
+        sample_weight_sqrt = None
+    return X, y, X_offset, y_offset, X_scale, sample_weight_sqrt
 
 
 def _rescale_data(X, y, sample_weight, inplace=False):
@@ -223,11 +228,15 @@ def _rescale_data(X, y, sample_weight, inplace=False):
         y_rescaled = sqrt(S) y
         X_rescaled = sqrt(S) X
 
+    The parameter `inplace` only takes effect for dense X and dense y.
+
     Returns
     -------
     X_rescaled : {array-like, sparse matrix}
 
     y_rescaled : {array-like, sparse matrix}
+
+    sample_weight_sqrt : array-like of shape (n_samples,)
     """
     # Assume that _validate_data and _check_sample_weight have been called by
     # the caller.
@@ -297,23 +306,21 @@ def predict(self, X):
         """
         return self._decision_function(X)
 
-    def _set_intercept(self, X_offset, y_offset, X_scale):
+    def _set_intercept(self, X_offset, y_offset, X_scale=None):
         """Set the intercept_"""
-
         xp, _ = get_namespace(X_offset, y_offset, X_scale)
 
         if self.fit_intercept:
             # We always want coef_.dtype=X.dtype. For instance, X.dtype can differ from
             # coef_.dtype if warm_start=True.
-            coef_ = xp.astype(self.coef_, X_scale.dtype, copy=False)
-            coef_ = self.coef_ = xp.divide(coef_, X_scale)
+            self.coef_ = xp.astype(self.coef_, X_offset.dtype, copy=False)
+            if X_scale is not None:
+                self.coef_ = xp.divide(self.coef_, X_scale)
 
-            if coef_.ndim == 1:
-                intercept_ = y_offset - X_offset @ coef_
+            if self.coef_.ndim == 1:
+                self.intercept_ = y_offset - X_offset @ self.coef_
             else:
-                intercept_ = y_offset - X_offset @ coef_.T
-
-            self.intercept_ = intercept_
+                self.intercept_ = y_offset - X_offset @ self.coef_.T
 
         else:
             self.intercept_ = 0.0
@@ -636,22 +643,14 @@ def fit(self, X, y, sample_weight=None):
         # sparse matrix. Therefore, let's not copy X when it is sparse.
         copy_X_in_preprocess_data = self.copy_X and not sp.issparse(X)
 
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
+        X, y, X_offset, y_offset, _, sample_weight_sqrt = _preprocess_data(
             X,
             y,
             fit_intercept=self.fit_intercept,
             copy=copy_X_in_preprocess_data,
             sample_weight=sample_weight,
         )
 
-        if has_sw:
-            # Sample weight can be implemented via a simple rescaling. Note
-            # that we safely do inplace rescaling when _preprocess_data has
-            # already made a copy if requested.
-            X, y, sample_weight_sqrt = _rescale_data(
-                X, y, sample_weight, inplace=copy_X_in_preprocess_data
-            )
-
         if self.positive:
             if y.ndim < 2:
                 self.coef_ = optimize.nnls(X, y)[0]
@@ -662,23 +661,21 @@ def fit(self, X, y, sample_weight=None):
                 )
                 self.coef_ = np.vstack([out[0] for out in outs])
         elif sp.issparse(X):
-            X_offset_scale = X_offset / X_scale
-
             if has_sw:
 
                 def matvec(b):
-                    return X.dot(b) - sample_weight_sqrt * b.dot(X_offset_scale)
+                    return X.dot(b) - sample_weight_sqrt * b.dot(X_offset)
 
                 def rmatvec(b):
-                    return X.T.dot(b) - X_offset_scale * b.dot(sample_weight_sqrt)
+                    return X.T.dot(b) - X_offset * b.dot(sample_weight_sqrt)
 
             else:
 
                 def matvec(b):
-                    return X.dot(b) - b.dot(X_offset_scale)
+                    return X.dot(b) - b.dot(X_offset)
 
                 def rmatvec(b):
-                    return X.T.dot(b) - X_offset_scale * b.sum()
+                    return X.T.dot(b) - X_offset * b.sum()
 
             X_centered = sparse.linalg.LinearOperator(
                 shape=X.shape, matvec=matvec, rmatvec=rmatvec
@@ -703,7 +700,7 @@ def rmatvec(b):
 
         if y.ndim == 1:
             self.coef_ = np.ravel(self.coef_)
-        self._set_intercept(X_offset, y_offset, X_scale)
+        self._set_intercept(X_offset, y_offset)
         return self
 
     def __sklearn_tags__(self):
@@ -790,35 +787,39 @@ def _pre_fit(
 
     This function applies _preprocess_data and additionally computes the gram matrix
     `precompute` as needed as well as `Xy`.
+
+    Returns
+    -------
+    X
+    y
+    X_offset
+    y_offset
+    X_scale
+    precompute
+    Xy
     """
     n_samples, n_features = X.shape
 
     if sparse.issparse(X):
         # copy is not needed here as X is not modified inplace when X is sparse
+        copy = False
         precompute = False
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
-            X,
-            y,
-            fit_intercept=fit_intercept,
-            copy=False,
-            check_input=check_input,
-            sample_weight=sample_weight,
-        )
+        # Rescale X and y only in dense case. Sparse cd solver directly deals with
+        # sample_weight.
+        rescale_with_sw = False
     else:
         # copy was done in fit if necessary
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
-            X,
-            y,
-            fit_intercept=fit_intercept,
-            copy=copy,
-            check_input=check_input,
-            sample_weight=sample_weight,
-        )
-        # Rescale only in dense case. Sparse cd solver directly deals with
-        # sample_weight.
-        if sample_weight is not None:
-            # This triggers copies anyway.
-            X, y, _ = _rescale_data(X, y, sample_weight=sample_weight)
+        rescale_with_sw = True
+
+    X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(
+        X,
+        y,
+        fit_intercept=fit_intercept,
+        copy=copy,
+        sample_weight=sample_weight,
+        check_input=check_input,
+        rescale_with_sw=rescale_with_sw,
+    )
 
     if hasattr(precompute, "__array__"):
         if fit_intercept and not np.allclose(X_offset, np.zeros(n_features)):
diff --git a/sklearn/linear_model/_bayes.py b/sklearn/linear_model/_bayes.py
--- a/sklearn/linear_model/_bayes.py
+++ b/sklearn/linear_model/_bayes.py
@@ -17,7 +17,7 @@
 from ..utils._param_validation import Interval
 from ..utils.extmath import fast_logdet
 from ..utils.validation import _check_sample_weight, validate_data
-from ._base import LinearModel, _preprocess_data, _rescale_data
+from ._base import LinearModel, _preprocess_data
 
 ###############################################################################
 # BayesianRidge regression
@@ -254,17 +254,15 @@ def fit(self, X, y, sample_weight=None):
             y_mean = np.average(y, weights=sample_weight)
             y_var = np.average((y - y_mean) ** 2, weights=sample_weight)
 
-        X, y, X_offset_, y_offset_, X_scale_ = _preprocess_data(
+        X, y, X_offset_, y_offset_, X_scale_, _ = _preprocess_data(
             X,
             y,
             fit_intercept=self.fit_intercept,
             copy=self.copy_X,
             sample_weight=sample_weight,
-        )
-
-        if sample_weight is not None:
             # Sample weight can be implemented via a simple rescaling.
-            X, y, _ = _rescale_data(X, y, sample_weight)
+            rescale_with_sw=True,
+        )
 
         self.X_offset_ = X_offset_
         self.X_scale_ = X_scale_
@@ -671,7 +669,7 @@ def fit(self, X, y):
         n_samples, n_features = X.shape
         coef_ = np.zeros(n_features, dtype=dtype)
 
-        X, y, X_offset_, y_offset_, X_scale_ = _preprocess_data(
+        X, y, X_offset_, y_offset_, X_scale_, _ = _preprocess_data(
             X, y, fit_intercept=self.fit_intercept, copy=self.copy_X
         )
 
diff --git a/sklearn/linear_model/_coordinate_descent.py b/sklearn/linear_model/_coordinate_descent.py
--- a/sklearn/linear_model/_coordinate_descent.py
+++ b/sklearn/linear_model/_coordinate_descent.py
@@ -149,13 +149,14 @@ def _alpha_grid(
     if Xy is not None:
         Xyw = Xy
     else:
-        X, y, X_offset, _, _ = _preprocess_data(
+        X, y, X_offset, _, _, _ = _preprocess_data(
             X,
             y,
             fit_intercept=fit_intercept,
             copy=copy_X,
             sample_weight=sample_weight,
             check_input=False,
+            rescale_with_sw=False,
         )
         if sample_weight is not None:
             if y.ndim > 1:
@@ -2688,7 +2689,7 @@ def fit(self, X, y):
         n_samples, n_features = X.shape
         n_targets = y.shape[1]
 
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
+        X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(
             X, y, fit_intercept=self.fit_intercept, copy=False
         )
 
diff --git a/sklearn/linear_model/_least_angle.py b/sklearn/linear_model/_least_angle.py
--- a/sklearn/linear_model/_least_angle.py
+++ b/sklearn/linear_model/_least_angle.py
@@ -1080,7 +1080,7 @@ def _fit(self, X, y, max_iter, alpha, fit_path, Xy=None):
         """Auxiliary method to fit the model using X, y as training data"""
         n_features = X.shape[1]
 
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
+        X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(
             X, y, fit_intercept=self.fit_intercept, copy=self.copy_X
         )
 
@@ -2244,7 +2244,7 @@ def fit(self, X, y, copy_X=None):
             copy_X = self.copy_X
         X, y = validate_data(self, X, y, force_writeable=True, y_numeric=True)
 
-        X, y, Xmean, ymean, Xstd = _preprocess_data(
+        X, y, Xmean, ymean, _, _ = _preprocess_data(
             X, y, fit_intercept=self.fit_intercept, copy=copy_X
         )
 
@@ -2306,7 +2306,7 @@ def fit(self, X, y, copy_X=None):
 
         self.alpha_ = alphas_[n_best]
         self.coef_ = coef_path_[:, n_best]
-        self._set_intercept(Xmean, ymean, Xstd)
+        self._set_intercept(Xmean, ymean)
         return self
 
     def _estimate_noise_variance(self, X, y, positive):
diff --git a/sklearn/linear_model/_ridge.py b/sklearn/linear_model/_ridge.py
--- a/sklearn/linear_model/_ridge.py
+++ b/sklearn/linear_model/_ridge.py
@@ -952,12 +952,13 @@ def fit(self, X, y, sample_weight=None):
             sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)
 
         # when X is sparse we only remove offset from y
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
+        X, y, X_offset, y_offset, X_scale, _ = _preprocess_data(
             X,
             y,
             fit_intercept=self.fit_intercept,
             copy=self.copy_X,
             sample_weight=sample_weight,
+            rescale_with_sw=False,
         )
 
         if solver == "sag" and sparse.issparse(X) and self.fit_intercept:
@@ -2139,12 +2140,13 @@ def fit(self, X, y, sample_weight=None, score_params=None):
         self.alphas = np.asarray(self.alphas)
 
         unscaled_y = y
-        X, y, X_offset, y_offset, X_scale = _preprocess_data(
+        X, y, X_offset, y_offset, X_scale, sqrt_sw = _preprocess_data(
             X,
             y,
             fit_intercept=self.fit_intercept,
             copy=self.copy_X,
             sample_weight=sample_weight,
+            rescale_with_sw=True,
         )
 
         gcv_mode = _check_gcv_mode(X, self.gcv_mode)
@@ -2162,9 +2164,7 @@ def fit(self, X, y, sample_weight=None, score_params=None):
 
         n_samples = X.shape[0]
 
-        if sample_weight is not None:
-            X, y, sqrt_sw = _rescale_data(X, y, sample_weight)
-        else:
+        if sqrt_sw is None:
             sqrt_sw = np.ones(n_samples, dtype=X.dtype)
 
         X_mean, *decomposition = decompose(X, y, sqrt_sw)